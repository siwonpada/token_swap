from stable_baselines3.common.callbacks import BaseCallback


class CurriculumCallback(BaseCallback):
    """
    ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµì„ ìœ„í•œ ì½œë°± í´ë˜ìŠ¤
    ë…¸ë“œ ê°œìˆ˜ë¥¼ ì ì§„ì ìœ¼ë¡œ ì¦ê°€ì‹œì¼œ í•™ìŠµ ë‚œì´ë„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        initial_node_num: int = 4,
        target_node_num: int = 20,
        success_threshold: float = 0.8,
        min_episodes_before_increase: int = 100,
        check_freq: int = 1000,
        verbose: int = 0,
    ):
        """
        Args:
            initial_node_num: ì‹œì‘ ë…¸ë“œ ê°œìˆ˜
            target_node_num: ëª©í‘œ ë…¸ë“œ ê°œìˆ˜
            success_threshold: ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ê¸° ìœ„í•œ ì„±ê³µë¥  ì„ê³„ê°’
            min_episodes_before_increase: ë…¸ë“œ ìˆ˜ ì¦ê°€ ì „ ìµœì†Œ ì—í”¼ì†Œë“œ ìˆ˜
            check_freq: ì„±ê³¼ í‰ê°€ ì£¼ê¸° (timesteps)
            verbose: ë¡œê·¸ ì¶œë ¥ ë ˆë²¨
        """
        super().__init__(verbose)
        self.initial_node_num = initial_node_num
        self.current_node_num = initial_node_num
        self.target_node_num = target_node_num
        self.success_threshold = success_threshold
        self.min_episodes_before_increase = min_episodes_before_increase
        self.check_freq = check_freq

        # í†µê³„ ì¶”ì ìš© ë³€ìˆ˜ë“¤
        self.episode_rewards = []
        self.episode_successes = []
        self.episodes_at_current_level = 0
        self.last_check_timestep = 0

        # ë…¸ë“œ ìˆ˜ ì¦ê°€ ë‹¨ê³„ ì •ì˜ (ì ì§„ì  ì¦ê°€)
        self.node_levels = self._generate_node_levels()
        self.current_level_idx = 0

    def _generate_node_levels(self) -> list:
        """ë…¸ë“œ ìˆ˜ ë‹¨ê³„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        if self.target_node_num <= self.initial_node_num:
            return [self.initial_node_num]

        # 2ê°œì”© ì ì§„ì ìœ¼ë¡œ ì¦ê°€
        levels = []
        current = self.initial_node_num
        while current <= self.target_node_num:
            levels.append(current)
            current += 2

        # ë§ˆì§€ë§‰ì´ targetê³¼ ë‹¤ë¥´ë©´ target ì¶”ê°€
        if levels[-1] != self.target_node_num:
            levels.append(self.target_node_num)

        return levels

    def _init_callback(self) -> None:
        """ì½œë°± ì´ˆê¸°í™”"""
        if self.verbose >= 1:
            print(f"ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµ ì‹œì‘: {self.initial_node_num}ê°œ ë…¸ë“œ")
            print(f"ë…¸ë“œ ìˆ˜ ë‹¨ê³„: {self.node_levels}")

    def _on_step(self) -> bool:
        """ë§¤ ìŠ¤í…ë§ˆë‹¤ í˜¸ì¶œë˜ëŠ” ë©”ì„œë“œ"""
        # ì—í”¼ì†Œë“œê°€ ëë‚¬ëŠ”ì§€ í™•ì¸
        if hasattr(self.locals, "dones") and any(self.locals["dones"]):
            self._on_episode_end()

        # ì£¼ê¸°ì ìœ¼ë¡œ ì„±ê³¼ í‰ê°€ ë° ë‚œì´ë„ ì¡°ì ˆ
        if self.num_timesteps - self.last_check_timestep >= self.check_freq:
            self._evaluate_and_adjust_difficulty()
            self.last_check_timestep = self.num_timesteps

        return True

    def _on_episode_end(self) -> None:
        """ì—í”¼ì†Œë“œ ì¢…ë£Œ ì‹œ í˜¸ì¶œ"""
        self.episodes_at_current_level += 1

        # ì—í”¼ì†Œë“œ í†µê³„ ìˆ˜ì§‘
        if hasattr(self.locals, "infos"):
            for info in self.locals["infos"]:
                if "episode" in info:
                    episode_reward = info["episode"]["r"]
                    episode_success = (
                        episode_reward > 0
                    )  # ì„±ê³µ ì—¬ë¶€ (ë³´ìƒì´ ì–‘ìˆ˜ë©´ ì„±ê³µ)

                    self.episode_rewards.append(episode_reward)
                    self.episode_successes.append(episode_success)

                    # ìµœê·¼ 100ê°œ ì—í”¼ì†Œë“œë§Œ ìœ ì§€
                    if len(self.episode_rewards) > 100:
                        self.episode_rewards.pop(0)
                        self.episode_successes.pop(0)

    def _evaluate_and_adjust_difficulty(self) -> None:
        """ì„±ê³¼ í‰ê°€ í›„ ë‚œì´ë„ ì¡°ì ˆ"""
        if (
            len(self.episode_successes) < 20  # ìµœì†Œ 20ê°œ ì—í”¼ì†Œë“œ í•„ìš”
            or self.episodes_at_current_level < self.min_episodes_before_increase
            or self.current_level_idx >= len(self.node_levels) - 1
        ):  # ì´ë¯¸ ìµœê³  ë‹¨ê³„
            return

        # ìµœê·¼ ì„±ê³µë¥  ê³„ì‚°
        recent_success_rate = sum(self.episode_successes[-50:]) / min(
            50, len(self.episode_successes)
        )

        if self.verbose >= 1:
            avg_reward = sum(self.episode_rewards[-20:]) / min(
                20, len(self.episode_rewards)
            )
            print(
                f"ë…¸ë“œ {self.current_node_num}ê°œ - ì„±ê³µë¥ : {recent_success_rate:.3f}, "
                f"í‰ê·  ë³´ìƒ: {avg_reward:.3f}, ì—í”¼ì†Œë“œ: {self.episodes_at_current_level}"
            )

        # ì„±ê³µë¥ ì´ ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ
        if recent_success_rate >= self.success_threshold:
            self._increase_difficulty()

    def _increase_difficulty(self) -> None:
        """ë‚œì´ë„ ì¦ê°€ (ë…¸ë“œ ìˆ˜ ì¦ê°€)"""
        if self.current_level_idx < len(self.node_levels) - 1:
            self.current_level_idx += 1
            self.current_node_num = self.node_levels[self.current_level_idx]
            self.episodes_at_current_level = 0

            # í™˜ê²½ ì—…ë°ì´íŠ¸
            self._update_environment()

            if self.verbose >= 1:
                print(f"ğŸ¯ ë‚œì´ë„ ì¦ê°€! ë…¸ë“œ ìˆ˜: {self.current_node_num}ê°œ")

    def _update_environment(self) -> None:
        """í™˜ê²½ì˜ ë…¸ë“œ ìˆ˜ ì—…ë°ì´íŠ¸"""
        try:
            # í™˜ê²½ì´ VecEnvì¸ ê²½ìš°
            if hasattr(self.training_env, "set_attr"):
                self.training_env.set_attr("node_num", self.current_node_num)
                if self.verbose >= 2:
                    print(f"VecEnv ë…¸ë“œ ìˆ˜ë¥¼ {self.current_node_num}ê°œë¡œ ì—…ë°ì´íŠ¸")

            # ë‹¨ì¼ í™˜ê²½ì¸ ê²½ìš° - ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ì†ì„± ì„¤ì •
            elif hasattr(self.training_env, "unwrapped"):
                env = self.training_env.unwrapped
                if hasattr(env, "node_num"):
                    setattr(env, "node_num", self.current_node_num)
                    if self.verbose >= 2:
                        print(
                            f"Unwrapped Env ë…¸ë“œ ìˆ˜ë¥¼ {self.current_node_num}ê°œë¡œ ì—…ë°ì´íŠ¸"
                        )

            # ì§ì ‘ ì ‘ê·¼ ì‹œë„
            else:
                # ëŸ°íƒ€ì„ì— ì†ì„± ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í›„ ì•ˆì „í•˜ê²Œ ì„¤ì •
                try:
                    if hasattr(self.training_env, "node_num"):
                        setattr(self.training_env, "node_num", self.current_node_num)
                        if self.verbose >= 2:
                            print(
                                f"Direct Env ë…¸ë“œ ìˆ˜ë¥¼ {self.current_node_num}ê°œë¡œ ì—…ë°ì´íŠ¸"
                            )
                except AttributeError:
                    pass  # ì†ì„± ì„¤ì • ì‹¤íŒ¨ëŠ” ë¬´ì‹œ

            # í™˜ê²½ ë¦¬ì…‹ (ìƒˆë¡œìš´ ë…¸ë“œ ìˆ˜ ì ìš©)
            if hasattr(self.training_env, "reset"):
                self.training_env.reset()

        except Exception as e:
            if self.verbose >= 1:
                print(f"í™˜ê²½ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print(
                    "í™˜ê²½ ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ í™˜ê²½ì„ ì¬ìƒì„±í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )

    def get_current_stats(self) -> dict:
        """í˜„ì¬ ì»¤ë¦¬í˜ëŸ¼ ìƒíƒœ ë°˜í™˜"""
        if len(self.episode_successes) > 0:
            recent_success_rate = sum(self.episode_successes[-20:]) / min(
                20, len(self.episode_successes)
            )
            avg_reward = sum(self.episode_rewards[-20:]) / min(
                20, len(self.episode_rewards)
            )
        else:
            recent_success_rate = 0.0
            avg_reward = 0.0

        return {
            "current_node_num": self.current_node_num,
            "current_level": self.current_level_idx + 1,
            "total_levels": len(self.node_levels),
            "episodes_at_level": self.episodes_at_current_level,
            "recent_success_rate": recent_success_rate,
            "recent_avg_reward": avg_reward,
            "progress": (self.current_level_idx + 1) / len(self.node_levels),
        }
