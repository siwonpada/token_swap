import gymnasium as gym
import os
from gymnasium.envs.registration import WrapperSpec
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback
from typing import Any, Dict

from src.callbacks.Curriculum_callback import CurriculumCallback

EX_NAME = "curriculum_experiment"
ENV_ID = "TokenSwapEnv-Curriculum"

# í™˜ê²½ ë“±ë¡
gym.register(
    id=ENV_ID,
    entry_point="src.envs:TokenSwapEnv",
    additional_wrappers=(
        WrapperSpec(
            "candidate_distance",
            "src.wrappers:CandidateDistanceWrapper",
            {
                "candidate_num": 10,  # ì´ˆê¸° í›„ë³´ ìˆ˜ (ì‘ê²Œ ì‹œì‘)
            },
        ),
    ),
)

N_TIMESTEPS = int(2e6)  # 2M timesteps
N_WORKERS = 8  # ë³‘ë ¬ í™˜ê²½ ìˆ˜

# PPO í•˜ì´í¼íŒŒë¼ë¯¸í„°
PPO_HYPERPARAMS: Dict[str, Any] = {
    "policy": "MlpPolicy",
    "learning_rate": 3e-4,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 10,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.0,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "verbose": 1,
}


def make_env(env_id: str, rank: int, seed: int = 0, node_num: int = 4):
    """í™˜ê²½ ìƒì„± í•¨ìˆ˜"""

    def _init():
        env = gym.make(env_id, node_num=node_num, seed=seed + rank)
        env = Monitor(env)
        return env

    return _init


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print(f"ğŸš€ ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµ ì‹¤í—˜ ì‹œì‘: {EX_NAME}")

    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    save_dir = f"result/{EX_NAME}"
    os.makedirs(save_dir, exist_ok=True)
    os.makedirs(f"{save_dir}/saves", exist_ok=True)

    # ì»¤ë¦¬í˜ëŸ¼ ì½œë°± ì„¤ì •
    curriculum_callback = CurriculumCallback(
        initial_node_num=4,  # 4ê°œ ë…¸ë“œë¡œ ì‹œì‘
        target_node_num=16,  # 16ê°œ ë…¸ë“œê¹Œì§€ ì¦ê°€
        success_threshold=0.7,  # 70% ì„±ê³µë¥  ë‹¬ì„± ì‹œ ë‹¤ìŒ ë‹¨ê³„ë¡œ
        min_episodes_before_increase=50,  # ìµœì†Œ 50 ì—í”¼ì†Œë“œ í›„ ì¦ê°€ ê³ ë ¤
        check_freq=5000,  # 5000 ìŠ¤í…ë§ˆë‹¤ í‰ê°€
        verbose=2,
    )

    # ì²´í¬í¬ì¸íŠ¸ ì½œë°± ì„¤ì •
    checkpoint_callback = CheckpointCallback(
        save_freq=50000, save_path=f"{save_dir}/saves/", name_prefix="curriculum_model"
    )

    # ì½œë°± ë¦¬ìŠ¤íŠ¸
    callbacks = CallbackList([curriculum_callback, checkpoint_callback])

    # ë³‘ë ¬ í™˜ê²½ ìƒì„±
    if N_WORKERS > 1:
        env = SubprocVecEnv([make_env(ENV_ID, i, node_num=4) for i in range(N_WORKERS)])
    else:
        env = DummyVecEnv([make_env(ENV_ID, 0, node_num=4)])

    # PPO ëª¨ë¸ ìƒì„±
    model = PPO(env=env, tensorboard_log=f"{save_dir}/", **PPO_HYPERPARAMS)

    print("ğŸ“Š ì´ˆê¸° ì»¤ë¦¬í˜ëŸ¼ ìƒíƒœ:")
    stats = curriculum_callback.get_current_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")

    # í•™ìŠµ ì‹œì‘
    print(f"ğŸ¯ í•™ìŠµ ì‹œì‘ - {N_TIMESTEPS:,} timesteps")
    try:
        model.learn(
            total_timesteps=N_TIMESTEPS,
            callback=callbacks,
            tb_log_name="curriculum_PPO",
        )

        # ìµœì¢… ëª¨ë¸ ì €ì¥
        model.save(f"{save_dir}/final_model")
        print(f"âœ… í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ì´ {save_dir}/final_model.zipì— ì €ì¥ë¨")

    except KeyboardInterrupt:
        print("\nâš ï¸ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        model.save(f"{save_dir}/interrupted_model")
        print(f"í˜„ì¬ ëª¨ë¸ì´ {save_dir}/interrupted_model.zipì— ì €ì¥ë¨")

    finally:
        # ìµœì¢… ì»¤ë¦¬í˜ëŸ¼ ìƒíƒœ ì¶œë ¥
        print("\nğŸ“ˆ ìµœì¢… ì»¤ë¦¬í˜ëŸ¼ ìƒíƒœ:")
        final_stats = curriculum_callback.get_current_stats()
        for key, value in final_stats.items():
            print(f"  {key}: {value}")

        env.close()


if __name__ == "__main__":
    main()
